@inproceedings{chen2016latent,
  title={Latent Attention For If-Then Program Synthesis},
  author={Chen, Xinyun and Liu, Chang and Shin, Richard and Song, Dawn and Chen, Mingcheng},
  booktitle={Proceedings of the 29th Advances in Neural Information Processing Systems},
  year={2016}
}
@inproceedings{quirk-etal-2015-language,
	title = "Language to Code: Learning Semantic Parsers for If-This-Then-That Recipes",
	author = "Quirk, Chris  and
	Mooney, Raymond  and
	Galley, Michel",
	booktitle = "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
	month = jul,
	year = "2015",
	address = "Beijing, China",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/P15-1085",
	doi = "10.3115/v1/P15-1085",
	pages = "878--888",
}

@inproceedings{beltagy-quirk-2016-improved,
	title = "Improved Semantic Parsers For If-Then Statements",
	author = "Beltagy, I.  and
	Quirk, Chris",
	booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
	month = aug,
	year = "2016",
	address = "Berlin, Germany",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/P16-1069",
	doi = "10.18653/v1/P16-1069",
	pages = "726--736",
}

@ARTICLE{JoeyNMT,
	author = {{Kreutzer}, Julia and {Bastings}, Joost and {Riezler}, Stefan},
	title = {Joey {NMT}: A Minimalist {NMT} Toolkit for Novices},
	journal = {To Appear in EMNLP-IJCNLP 2019: System Demonstrations},
	year = {2019},
	month = {Nov},
	address = {Hong Kong}
	url = {https://arxiv.org/abs/1907.12484}
}

@inproceedings{klein-etal-2018-opennmt,
	title = "{O}pen{NMT}: Neural Machine Translation Toolkit",
	author = "Klein, Guillaume  and
	Kim, Yoon  and
	Deng, Yuntian  and
	Nguyen, Vincent  and
	Senellart, Jean  and
	Rush, Alexander",
	booktitle = "Proceedings of the 13th Conference of the Association for Machine Translation in the {A}mericas (Volume 1: Research Papers)",
	month = mar,
	year = "2018",
	address = "Boston, MA",
	publisher = "Association for Machine Translation in the Americas",
	url = "https://www.aclweb.org/anthology/W18-1817",
	pages = "177--184",
}

@article{DBLP:journals/corr/LuongPM15,
	author    = {Minh{-}Thang Luong and
	Hieu Pham and
	Christopher D. Manning},
	title     = {Effective Approaches to Attention-based Neural Machine Translation},
	journal   = {CoRR},
	volume    = {abs/1508.04025},
	year      = {2015},
	url       = {http://arxiv.org/abs/1508.04025},
	archivePrefix = {arXiv},
	eprint    = {1508.04025},
	timestamp = {Mon, 13 Aug 2018 16:46:14 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/LuongPM15},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@incollection{NIPS2017_7181,
	title = {Attention is All you Need},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
	booktitle = {Advances in Neural Information Processing Systems 30},
	editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	pages = {5998--6008},
	year = {2017},
	publisher = {Curran Associates, Inc.},
	url = {http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf}
}

@misc{bahdanau2014neural,
	abstract = {Neural machine translation is a recently proposed approach to machine
	translation. Unlike the traditional statistical machine translation, the neural
	machine translation aims at building a single neural network that can be
	jointly tuned to maximize the translation performance. The models proposed
	recently for neural machine translation often belong to a family of
	encoder-decoders and consists of an encoder that encodes a source sentence into
	a fixed-length vector from which a decoder generates a translation. In this
	paper, we conjecture that the use of a fixed-length vector is a bottleneck in
	improving the performance of this basic encoder-decoder architecture, and
	propose to extend this by allowing a model to automatically (soft-)search for
	parts of a source sentence that are relevant to predicting a target word,
	without having to form these parts as a hard segment explicitly. With this new
	approach, we achieve a translation performance comparable to the existing
	state-of-the-art phrase-based system on the task of English-to-French
	translation. Furthermore, qualitative analysis reveals that the
	(soft-)alignments found by the model agree well with our intuition.},
	added-at = {2018-06-20T16:45:50.000+0200},
	author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
	biburl = {https://www.bibsonomy.org/bibtex/2713375898fd7d2477f6ab6dc3dd66c2c/albinzehe},
	description = {[1409.0473] Neural Machine Translation by Jointly Learning to Align and Translate},
	interhash = {bb2ca011eeafccb0bd2505c9476dcd10},
	intrahash = {713375898fd7d2477f6ab6dc3dd66c2c},
	keywords = {attention mlnlp neuralnet rnn},
	note = {cite arxiv:1409.0473Comment: Accepted at ICLR 2015 as oral presentation},
	timestamp = {2018-06-20T16:45:50.000+0200},
	title = {Neural Machine Translation by Jointly Learning to Align and Translate},
	url = {http://arxiv.org/abs/1409.0473},
	year = 2014
}

@ARTICLE{JoeyNMT,
	author = {{Kreutzer}, Julia and {Bastings}, Joost and {Riezler}, Stefan},
	title = {Joey {NMT}: A Minimalist {NMT} Toolkit for Novices},
	journal = {To Appear in EMNLP-IJCNLP 2019: System Demonstrations},
	year = {2019},
	month = {Nov},
	address = {Hong Kong}
	url = {https://arxiv.org/abs/1907.12484}
}

@inproceedings{luong-etal-2015-effective,
	title = "Effective Approaches to Attention-based Neural Machine Translation",
	author = "Luong, Thang  and
	Pham, Hieu  and
	Manning, Christopher D.",
	booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
	month = sep,
	year = "2015",
	address = "Lisbon, Portugal",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/D15-1166",
	doi = "10.18653/v1/D15-1166",
	pages = "1412--1421",
}


@article{DBLP:journals/corr/abs-1804-04235,
	author    = {Noam Shazeer and
	Mitchell Stern},
	title     = {Adafactor: Adaptive Learning Rates with Sublinear Memory Cost},
	journal   = {CoRR},
	volume    = {abs/1804.04235},
	year      = {2018},
	url       = {http://arxiv.org/abs/1804.04235},
	archivePrefix = {arXiv},
	eprint    = {1804.04235},
	timestamp = {Mon, 13 Aug 2018 16:48:15 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1804-04235},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1808-06740,
	author    = {Ziyu Yao and
	Xiujun Li and
	Jianfeng Gao and
	Brian M. Sadler and
	Huan Sun},
	title     = {Interactive Semantic Parsing for If-Then Recipes via Hierarchical
	Reinforcement Learning},
	journal   = {CoRR},
	volume    = {abs/1808.06740},
	year      = {2018},
	url       = {http://arxiv.org/abs/1808.06740},
	archivePrefix = {arXiv},
	eprint    = {1808.06740},
	timestamp = {Sun, 02 Sep 2018 15:01:55 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1808-06740},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Lin2017ProgramSF,
	title={Program Synthesis from Natural Language Using Recurrent Neural Networks},
	author={Xi Victoria Lin},
	year={2017}
}

@inproceedings{krishnamurthy-etal-2017-neural,
	title = "Neural Semantic Parsing with Type Constraints for Semi-Structured Tables",
	author = "Krishnamurthy, Jayant  and
	Dasigi, Pradeep  and
	Gardner, Matt",
	booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
	month = sep,
	year = "2017",
	address = "Copenhagen, Denmark",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/D17-1160",
	doi = "10.18653/v1/D17-1160",
	pages = "1516--1526",
	abstract = "We present a new semantic parsing model for answering compositional questions on semi-structured Wikipedia tables. Our parser is an encoder-decoder neural network with two key technical innovations: (1) a grammar for the decoder that only generates well-typed logical forms; and (2) an entity embedding and linking module that identifies entity mentions while generalizing across tables. We also introduce a novel method for training our neural model with question-answer supervision. On the WikiTableQuestions data set, our parser achieves a state-of-the-art accuracy of 43.3{\%} for a single model and 45.9{\%} for a 5-model ensemble, improving on the best prior score of 38.7{\%} set by a 15-model ensemble. These results suggest that type constraints and entity linking are valuable components to incorporate in neural semantic parsers.",
}

@article{DBLP:journals/corr/SutskeverVL14,
	author    = {Ilya Sutskever and
	Oriol Vinyals and
	Quoc V. Le},
	title     = {Sequence to Sequence Learning with Neural Networks},
	journal   = {CoRR},
	volume    = {abs/1409.3215},
	year      = {2014},
	url       = {http://arxiv.org/abs/1409.3215},
	archivePrefix = {arXiv},
	eprint    = {1409.3215},
	timestamp = {Mon, 13 Aug 2018 16:48:06 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/SutskeverVL14},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
